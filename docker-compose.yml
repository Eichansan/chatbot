version: "3.9"

services:
  chainlit:
    container_name: chainlit
    build: ./docker/chainlit
    volumes:
      - ./app:/var/www/app
    restart: always
    environment:
      - QDRANT_HOST=${QDRANT_HOST}
      - QDRANT_PORT=${QDRANT_PORT}
      - QDRANT_COLLECTION=${QDRANT_COLLECTION}
      # 下二つなんで必要なのかわからねぇ...
      - OLLAMA_HOST=${OLLAMA_HOST}
      - OLLAMA_PORT=${OLLAMA_PORT}
      - OLLAMA_EMBEDDINGS_MODEL=${OLLAMA_EMBEDDINGS_MODEL}
      - OLLAMA_LLM=${OLLAMA_LLM}
    ports:
      - "3000:3000"
    command: chainlit run /var/www/app/chainlit_app.py --host 0.0.0.0 --port 3000 -w

  fastapi:
    container_name: fastapi
    build: ./docker/fastapi
    volumes:
      - ./app:/var/www/app
    restart: always
    depends_on:
      - ollama
    ports:
      - "8000:8000"
    environment:
      - QDRANT_HOST=${QDRANT_HOST}
      - QDRANT_PORT=${QDRANT_PORT}
      - QDRANT_COLLECTION=${QDRANT_COLLECTION}
      - OLLAMA_HOST=${OLLAMA_HOST}
      - OLLAMA_PORT=${OLLAMA_PORT}
      - OLLAMA_EMBEDDINGS_MODEL=${OLLAMA_EMBEDDINGS_MODEL}
      - OLLAMA_LLM=${OLLAMA_LLM}
    command: uvicorn main:app --reload --host 0.0.0.0 --port 8000

  ollama:
    image: ollama/ollama
    container_name: ollama
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    volumes:
      - ollama:/root/.ollama
    ports:
      - "11434:11434"

  qdrant:
    image: qdrant/qdrant
    container_name: qdrant
    restart: always
    ports:
      - "6333:6333"
    volumes:
      - qdrant_storage:/qdrant/storage

volumes:
  ollama:
  qdrant_storage:
